{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xception.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Xception\n",
        "\n"
      ],
      "metadata": {
        "id": "jVgZWL2EJBvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUYp1X_4I1UC"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montamos el directorio Drive para cargar las imágenes\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "552P-oiWJOaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de las imágenes\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "CHANNELS = 3\n",
        "N_CLASSES = 29\n",
        "TRAIN_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Sentinel2LULC_354/Sentinel2LULC_354/\"\n",
        "AUG_TRAIN_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Sentinel2LULC_354_augmented/Sentinel2LULC_354_augmented/\"\n",
        "TEST_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Test 2\"\n",
        "\n",
        "# Parámetros de entrenamiento\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 1e-3 #1e-4 #1e-5\n",
        "LOSS = 'categorical_crossentropy'\n",
        "# Métricas a mostrar en las gráficas\n",
        "METRICS = ['accuracy', 'AUC']"
      ],
      "metadata": {
        "id": "uXKnrrJTJSWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conjunto de entrenamiento original\n"
      ],
      "metadata": {
        "id": "WvWoFgCZJeEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "htgRMEI6Jl2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "H1BLxT2RJoP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, \n",
        "                                         validation_split=0.2,\n",
        "                                         rotation_range=45,\n",
        "                                         width_shift_range=.15,\n",
        "                                         height_shift_range=.15,\n",
        "                                         horizontal_flip=True,\n",
        "                                         vertical_flip=True,\n",
        "                                         zoom_range=0.5)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "A0lIjc6AJqRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation + Conjunto de entrenamiento original"
      ],
      "metadata": {
        "id": "0cXTZzk-JumU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=AUG_TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "k5I33AisJ0Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga del modelo"
      ],
      "metadata": {
        "id": "MXhMyBvxJ7CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo Xception con los pesos de haber sido enterenado con ImageNET\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
        "print(\"Nº de capas: \", len(base_model.layers))"
      ],
      "metadata": {
        "id": "WMNpKQAcKAm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando los pesos originales"
      ],
      "metadata": {
        "id": "raQsIUQxKEkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRIMERA VERSIÓN: sin re-entrenar ninguna capa\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "xJgU6gmJKLRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-entrenando algunas capas"
      ],
      "metadata": {
        "id": "Kfe7MTr8KM0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEGUNDA VERSIÓN: finetuning re-entrenando algunas capas\n",
        "base_model.trainable = True\n",
        "# Número de capas a re-entrenar\n",
        "fine_tune_at = 100 #10 #50\n",
        "# Congelamos los pesos de todas las capas anteriores a las que se van a re-entrenar\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "metadata": {
        "id": "vHePPWQ_KPWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando el modelo completo"
      ],
      "metadata": {
        "id": "3fNzAqBIKRhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TERCERA VERSIÓN: re-entrenando todas las capas\n",
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "70X_lSojKTr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adaptación del modelo"
      ],
      "metadata": {
        "id": "1jkz45GqKjQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptamos el modelo a nuestro problema\n",
        "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='input_image')\n",
        "output_conv = base_model(input_layer)\n",
        "x = Flatten(name='flatten')(output_conv) \n",
        "#x = Dense(128, activation='relu', name='dense_128')(x)\n",
        "#x = Dropout(.1, input_shape=(128,), name='dropout_128')(x)\n",
        "#x = Dense(64, activation='relu', name='dense_64')(x)\n",
        "#x = Dropout(.1, input_shape=(64,), name='dropout_64')(x)\n",
        "# Última capa de salida con las 29 clases\n",
        "x = Dense(N_CLASSES, activation='softmax', name='classes')(x)"
      ],
      "metadata": {
        "id": "l4EMyA4bKo-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación del modelo"
      ],
      "metadata": {
        "id": "-bfLRxv4KZqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer, outputs=x)\n",
        "opt = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss=LOSS, metrics=METRICS)\n",
        "history = model.fit(train_it,\n",
        "          validation_data=validation_it,\n",
        "          steps_per_epoch=train_it.n // BATCH_SIZE,\n",
        "          validation_steps=validation_it.n // BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          workers=100,\n",
        "          use_multiprocessing=True)\n",
        "# Guardamos el modelo en un fichero\n",
        "# model_filename = \"xception_dataaugv2_all_1e4.h5\"\n",
        "# model.save(model_filename)"
      ],
      "metadata": {
        "id": "D-6yPMvHKdtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicciones sobre test"
      ],
      "metadata": {
        "id": "dD4MdaKwKzpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos las imágenes de test\n",
        "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
        "test_it = test_datagenerator.flow_from_directory(directory=TEST_DIR,\n",
        "                                                  target_size=(HEIGHT, WIDTH),\n",
        "                                                  batch_size= 1,\n",
        "                                                  class_mode=None,\n",
        "                                                  shuffle=False)\n",
        "# Reseteamos el iterador sobre las imágenes de test\n",
        "test_it.reset()\n",
        "\n",
        "# Predecimos con el modelo entrenado sobre las imágenes de test\n",
        "test_probs = model.predict(test_it, steps=test_it.samples)\n",
        "test_preds = np.argmax(test_probs, axis=1)\n",
        "print(\"\\nPredicciones: \", test_preds)\n",
        "\n",
        "# Construimos un traductor entre las etiquetas automáticamente generadas por Keras\n",
        "# y las reales a partir de los nombres de las carpetas de entrenamiento\n",
        "translated_train_labels = {train_it.class_indices[key]:int(key[:key.index(\"_\")]) \n",
        "                        for key in train_it.class_indices}\n",
        "print(\"\\nEtiquetas train: \", translated_train_labels)\n",
        "\n",
        "# Traducimos las etiquetas de test resultantes a las reales\n",
        "translated_test_preds = [translated_train_labels[label] for label in test_preds]\n",
        "print(\"\\nPredicciones reales: \", translated_test_preds)\n",
        "\n",
        "# Creamos el fichero de subida\n",
        "id_jpg_column = [test_img[(test_img.find(\"/\") + 1): ] for test_img in test_it.filenames]\n",
        "preds_dataset = pd.DataFrame({'id.jpg': id_jpg_column, 'label': translated_test_preds})\n",
        "preds_filename = \"submission_trained_xception.csv\"\n",
        "preds_dataset.to_csv(preds_filename, index=False)"
      ],
      "metadata": {
        "id": "Mapn0MHvKxOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gráfica de evolución "
      ],
      "metadata": {
        "id": "qEknMSFmK6hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica de la evolución de entrenamiento y validación durante las épocas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "metadata": {
        "id": "q37sZwphK9E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}