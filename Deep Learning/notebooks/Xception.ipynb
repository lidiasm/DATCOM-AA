{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Xception\n",
        "\n"
      ],
      "metadata": {
        "id": "jVgZWL2EJBvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUYp1X_4I1UC"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, Nadam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montamos el directorio Drive para cargar las imágenes\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "552P-oiWJOaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23b0e80-3717-49f2-e729-333cc2609802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de las imágenes\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "CHANNELS = 3\n",
        "N_CLASSES = 29\n",
        "TRAIN_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Sentinel2LULC_354/Sentinel2LULC_354/\"\n",
        "AUG_TRAIN_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Sentinel2LULC_354_augmented/Sentinel2LULC_354_augmented/\"\n",
        "TEST_DIR = \"/content/gdrive/MyDrive/Backup/DATCOM/AA/Test 2\"\n",
        "\n",
        "# Parámetros de entrenamiento\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100 #10 #25 #35\n",
        "LEARNING_RATE = 1e-4 #1e-3 #1e-4 #1e-5\n",
        "LOSS = 'categorical_crossentropy'\n",
        "# Métricas a mostrar en las gráficas\n",
        "METRICS = ['accuracy', 'AUC']"
      ],
      "metadata": {
        "id": "uXKnrrJTJSWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conjunto de entrenamiento original\n"
      ],
      "metadata": {
        "id": "WvWoFgCZJeEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "htgRMEI6Jl2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "H1BLxT2RJoP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, \n",
        "                                         validation_split=0.2,\n",
        "                                         rotation_range=45,\n",
        "                                         width_shift_range=.15,\n",
        "                                         height_shift_range=.15,\n",
        "                                         horizontal_flip=True,\n",
        "                                         vertical_flip=True,\n",
        "                                         zoom_range=0.5)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "A0lIjc6AJqRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation + Conjunto de entrenamiento original"
      ],
      "metadata": {
        "id": "0cXTZzk-JumU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos las imágenes de entrenamiento y las dividimos en 80% para entrenamiento\n",
        "# del modelo y 20% para validación \n",
        "train_datagenerator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "train_it = train_datagenerator.flow_from_directory(directory=AUG_TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    subset='training')\n",
        "validation_it = train_datagenerator.flow_from_directory(directory=AUG_TRAIN_DIR,\n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "id": "k5I33AisJ0Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga del modelo"
      ],
      "metadata": {
        "id": "MXhMyBvxJ7CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo con los pesos del entrenamiento sobre ImageNet\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
        "print(\"Nº de capas: \", len(base_model.layers))"
      ],
      "metadata": {
        "id": "WMNpKQAcKAm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando los pesos originales"
      ],
      "metadata": {
        "id": "raQsIUQxKEkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRIMERA VERSIÓN: sin re-entrenar ninguna capa\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "xJgU6gmJKLRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-entrenando algunas capas"
      ],
      "metadata": {
        "id": "Kfe7MTr8KM0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEGUNDA VERSIÓN: finetuning re-entrenando algunas capas\n",
        "base_model.trainable = True\n",
        "# Número de capas a re-entrenar\n",
        "fine_tune_at = 100 #10 #50\n",
        "# Congelamos los pesos de todas las capas anteriores a las que se van a re-entrenar\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "metadata": {
        "id": "vHePPWQ_KPWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando el modelo completo"
      ],
      "metadata": {
        "id": "3fNzAqBIKRhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TERCERA VERSIÓN: re-entrenando todas las capas\n",
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "70X_lSojKTr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaptación del modelo"
      ],
      "metadata": {
        "id": "1jkz45GqKjQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tradicional"
      ],
      "metadata": {
        "id": "LTWwwl6mtWAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptamos el modelo a nuestro problema\n",
        "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='input_image')\n",
        "output_conv = base_model(input_layer)\n",
        "x = Flatten(name='flatten')(output_conv) \n",
        "# Última capa de salida con las 29 clases\n",
        "x = Dense(N_CLASSES, activation='softmax', name='classes')(x)"
      ],
      "metadata": {
        "id": "l4EMyA4bKo-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularización L1"
      ],
      "metadata": {
        "id": "lFudqo_utYfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptamos el modelo a nuestro problema\n",
        "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='input_image')\n",
        "output_conv = base_model(input_layer)\n",
        "x = Flatten(name='flatten')(output_conv) \n",
        "# Última capa de salida con las 29 clases\n",
        "x = Dense(N_CLASSES, activation='softmax', name='classes', kernel_regularizer=l1(0.1))(x)"
      ],
      "metadata": {
        "id": "oVMXlC_Ctalj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularización L2"
      ],
      "metadata": {
        "id": "6qLOtHVD55bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptamos el modelo a nuestro problema\n",
        "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='input_image')\n",
        "output_conv = base_model(input_layer)\n",
        "x = Flatten(name='flatten')(output_conv) \n",
        "# Última capa de salida con las 29 clases\n",
        "x = Dense(N_CLASSES, activation='softmax', name='classes', kernel_regularizer=l2(0.1))(x)"
      ],
      "metadata": {
        "id": "9D-bqsSc57NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularización L1 y L2"
      ],
      "metadata": {
        "id": "bFzp-AZw5_Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptamos el modelo a nuestro problema\n",
        "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='input_image')\n",
        "output_conv = base_model(input_layer)\n",
        "x = Flatten(name='flatten')(output_conv) \n",
        "# Última capa de salida con las 29 clases\n",
        "x = Dense(N_CLASSES, activation='softmax', name='classes', kernel_regularizer=l1_l2(l1=0.1, l2=0.1))(x)"
      ],
      "metadata": {
        "id": "MMkEzZV76A7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilación del modelo"
      ],
      "metadata": {
        "id": "-bfLRxv4KZqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizador Adam"
      ],
      "metadata": {
        "id": "G_xLTidi6y10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer, outputs=x)\n",
        "opt = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss=LOSS, metrics=METRICS)"
      ],
      "metadata": {
        "id": "nE-nGs9QWfAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizador Adamax"
      ],
      "metadata": {
        "id": "GIhOWk4Z8EUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer, outputs=x)\n",
        "opt = Adamax(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss=LOSS, metrics=METRICS)"
      ],
      "metadata": {
        "id": "ny2d_Ezp8H7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizador Nadam"
      ],
      "metadata": {
        "id": "kllGnKsJqg7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer, outputs=x)\n",
        "opt = Nadam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss=LOSS, metrics=METRICS)"
      ],
      "metadata": {
        "id": "anCMDrcKqiTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "11A9s_pgWcc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento tradicional"
      ],
      "metadata": {
        "id": "V4PlJcoj00ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_it,\n",
        "          validation_data=validation_it,\n",
        "          steps_per_epoch=train_it.n // BATCH_SIZE,\n",
        "          validation_steps=validation_it.n // BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          workers=100,\n",
        "          use_multiprocessing=True)\n",
        "# Guardamos el modelo en un fichero\n",
        "model_filename = \"xception_model.h5\"\n",
        "model.save(model_filename)"
      ],
      "metadata": {
        "id": "D-6yPMvHKdtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early Stopping"
      ],
      "metadata": {
        "id": "IvqUnsJ6QZJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_it,\n",
        "          validation_data=validation_it,\n",
        "          steps_per_epoch=train_it.n // BATCH_SIZE,\n",
        "          validation_steps=validation_it.n // BATCH_SIZE,\n",
        "          callbacks=[EarlyStopping(\n",
        "            monitor=\"val_accuracy\", \n",
        "            patience=10, \n",
        "            mode=\"auto\",\n",
        "            restore_best_weights=True)],\n",
        "          epochs=EPOCHS,\n",
        "          workers=100,\n",
        "          use_multiprocessing=True)\n",
        "# Guardamos el modelo en un fichero\n",
        "model_filename = \"xception_model.h5\"\n",
        "model.save(model_filename)"
      ],
      "metadata": {
        "id": "iN0CONjobWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gráfica de la evolución del entrenamiento"
      ],
      "metadata": {
        "id": "dTFU7UsK1KDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica de evolución de la tasa de acierto durante entrenamiento y validación\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "metadata": {
        "id": "6dltv_mF1CDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicciones sobre test"
      ],
      "metadata": {
        "id": "dD4MdaKwKzpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos las imágenes de test\n",
        "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
        "test_it = test_datagenerator.flow_from_directory(directory=TEST_DIR,\n",
        "                                                  target_size=(HEIGHT, WIDTH),\n",
        "                                                  batch_size= 1,\n",
        "                                                  class_mode=None,\n",
        "                                                  shuffle=False)\n",
        "# Reseteamos el iterador sobre las imágenes de test\n",
        "test_it.reset()\n",
        "\n",
        "# Predecimos con el modelo entrenado sobre las imágenes de test\n",
        "test_probs = model.predict(test_it, steps=test_it.samples)\n",
        "test_preds = np.argmax(test_probs, axis=1)\n",
        "\n",
        "# Construimos un traductor entre las etiquetas automáticamente generadas por Keras\n",
        "# y las reales a partir de los nombres de las carpetas de entrenamiento\n",
        "translated_train_labels = {train_it.class_indices[key]:int(key[:key.index(\"_\")]) \n",
        "                        for key in train_it.class_indices}\n",
        "# Traducimos las etiquetas de test resultantes a las reales\n",
        "translated_test_preds = [translated_train_labels[label] for label in test_preds]\n",
        "\n",
        "# Creamos el fichero de subida\n",
        "id_jpg_column = [test_img[(test_img.find(\"/\") + 1): ] for test_img in test_it.filenames]\n",
        "preds_dataset = pd.DataFrame({'id.jpg': id_jpg_column, 'label': translated_test_preds})\n",
        "preds_filename = \"xception_submission.csv\"\n",
        "preds_dataset.to_csv(preds_filename, index=False)"
      ],
      "metadata": {
        "id": "Mapn0MHvKxOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}